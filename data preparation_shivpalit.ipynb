{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data\n",
    "import pandas as pd\n",
    "from iexfinance.stocks import Stock\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Investor Sentiment data\n",
    "quandl.ApiConfig.api_key = 'YXv7ndtD_deGW9xeR4s8'\n",
    "df = quandl.get('AAII/AAII_SENTIMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the date into a column rather than index and then to 'datetime' object type\n",
    "df.reset_index(level = 0, inplace = True)\n",
    "df.Date=pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping missing values\n",
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting USDX data\n",
    "usdx = pd.read_csv('https://www.quandl.com/api/v3/datasets/CHRIS/ICE_DX1.csv?api_key=YXv7ndtD_deGW9xeR4s8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary values from the investor sentiment data\n",
    "df2 = df2.drop(['Total','Bullish Average',\n",
    "                'Bullish Average + St. Dev','Bullish Average - St. Dev'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USDX date to 'datetime' object type\n",
    "usdx['Date'] = pd.to_datetime(usdx['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging USDX to the investor sentiment data\n",
    "df2 = df2.merge(usdx[['Date','Open','High','Low','Settle','Change']], on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating change in S&P500 weekly close\n",
    "ch = [0]\n",
    "ch1 = [((j-i)/i) for i, j in zip(df2['S&P 500 Weekly Close'][:-1], df2['S&P 500 Weekly Close'][1:])]\n",
    "for i in ch1:\n",
    "    ch.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding S&P500 change to the dataset\n",
    "df2['SP week %change'] = ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unncessary data\n",
    "df3 = df2.drop(['Bullish','Neutral','Bearish'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting USTB data\n",
    "ustb = pd.read_csv('https://www.quandl.com/api/v3/datasets/CHRIS/CME_US1.csv?api_key=YXv7ndtD_deGW9xeR4s8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing USTB date to 'datetime' object type\n",
    "ustb['Date'] = pd.to_datetime(ustb['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing names of columns\n",
    "ustb = ustb.rename(index=str, columns={'Last':'USTB last', 'Change':'USTB change', 'Settle':'USTB settle'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging USTB to the investor sentiment dataset\n",
    "df3 = df3.merge(ustb[['USTB last','USTB change','USTB settle','Date']],on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming column\n",
    "df3 = df3.rename(index = str, columns={'Settle':'USDX settle'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary values\n",
    "df3 = df3.drop(['Change'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the S&P500 data that was taken from Yahoo Finance and then used to calculate MACD\n",
    "sp5 = pd.read_csv('sp5 data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the S&P500 date to 'datetime' object\n",
    "sp5.Date = pd.to_datetime(sp5.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the S&P500 Yahoo data to the dataset\n",
    "df4 = df3.merge(sp5[['SP5 12 day SMA','SP5 26 day SMA','SP5 12 day EMA','SP5 26 day EMA','SP5 MACD', 'Date']], on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary variables\n",
    "df4 = df4.drop(['Open','High','Low','USTB change','USTB last'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the weekly change in USDX futures price\n",
    "ch2 = [0]\n",
    "ch3 = [((j-i)/i) for i, j in zip(df4['USDX settle'][:-1], df4['USDX settle'][1:])]\n",
    "for i in ch3:\n",
    "    ch2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the USDX change to the dataset\n",
    "df4['USDX %change']=ch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the weekly change in USTB futures price\n",
    "ch4 = [0]\n",
    "ch5 = [((j-i)/i) for i, j in zip(df4['USTB settle'][:-1], df4['USTB settle'][1:])]\n",
    "for i in ch5:\n",
    "    ch4.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the USTB change to the dataset\n",
    "df4['USTB %change'] = ch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using only the data that occurs after January 1, 2001 for my dataset\n",
    "df4 = df4[df4['Date']>='2000-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the S&P500 volatility\n",
    "vol = (df4['S&P 500 Weekly High']-df4['S&P 500 Weekly Low'])/df4['S&P 500 Weekly Close']\n",
    "df4['sp volatility'] = vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the DJI data that was taken from Yahoo Finance and then used to calculate MACD\n",
    "dji = pd.read_csv('dji data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary variables to create the feature set\n",
    "dfX = df4.drop(['S&P 500 Weekly High','S&P 500 Weekly Low',\n",
    "                'Bullish 8-Week Mov Avg','Bull-Bear Spread','SP5 12 day SMA','SP5 26 day SMA',\n",
    "                'SP5 12 day EMA','SP5 26 day EMA','S&P 500 Weekly Close','USDX settle','USTB settle'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the DJI date to'datetime' object\n",
    "dji.Date = pd.to_datetime(dji['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using only necessary variables\n",
    "dji2 = dji[['Date','DJI MACD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the DJI to the feature set\n",
    "dfX = dfX.merge(dji2,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the class set\n",
    "dfY = df4[['Date','Bull-Bear Spread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the discrete variable for the class\n",
    "v = pd.cut(dfY['Bull-Bear Spread'], bins=2, labels=np.arange(2), right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivpalit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#adding the discrete variable to the class set\n",
    "dfY['cat bull-bear'] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the feature and class datasets\n",
    "dfXY = dfX.merge(dfY, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the NASDAQ composite Yahoo Finance data and changing the date to 'datetime' object\n",
    "ix = pd.read_csv('IXIC data.csv')\n",
    "ix.Date = pd.to_datetime(ix.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the IXIC MACD to the feature and class dataset\n",
    "dfXY = dfXY.merge(ix[['IXIC MACD','Date']], on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to a csv file to use for the analysis\n",
    "dfXY.to_csv('final_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
